
import os
import re
import json
from string import Template
import asyncio

import click
from dotenv import load_dotenv
from openai import OpenAI
import platform

from prompt_template import react_system_prompt_template
from mcp_client import MCPClient


class ReActAgent:
    def __init__(self, mcp_client:MCPClient, model: str, project_directory: str):
        self.mcp_client = mcp_client
        self.model = model
        self.project_directory = project_directory
        self.client = OpenAI(
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            api_key=ReActAgent.get_api_key(),
        )
        self.tools = []

    async def initialize(self):
        """åˆå§‹åŒ–å·¥å…·ä¿¡æ¯"""
        self.tools = [{
            "type": "function",  # æ·»åŠ ç±»å‹æ ‡è¯†
            "function": {  # å‡½æ•°ä¿¡æ¯åŒ…è£¹åœ¨functionå­—æ®µä¸­
                "name": tool.name,
                "description": tool.description,
                "parameters": tool.inputSchema  # åŸinput_schemaå¯¹åº”parameterså­—æ®µ
            }
        } for tool in self.mcp_client.tools]

    async def run(self, user_input: str):
        messages = [
            # ç³»ç»Ÿæç¤ºè¯
            {"role": "system", "content": self.render_system_prompt(react_system_prompt_template)},
            # ç”¨æˆ·æå‡ºçš„é—®é¢˜
            {"role": "user", "content": f"<question>{user_input}</question>"}
        ]

        while True:

            # è¯·æ±‚æ¨¡å‹
            content = self.call_model(messages)

            # æ£€æµ‹ Thoughtï¼Œä»contentå­—ç¬¦ä¸²ä¸­æŸ¥æ‰¾å¹¶æå–è¢«<thought>å’Œ</thought>æ ‡ç­¾åŒ…è£¹çš„å†…å®¹
            # re.DOTALLï¼šæ ‡å¿—ä½ï¼Œä½¿.å¯ä»¥åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦åœ¨å†…çš„æ‰€æœ‰å­—ç¬¦
            thought_match = re.search(r"<thought>(.*?)</thought>", content, re.DOTALL)
            if thought_match:
                thought = thought_match.group(1)
                print(f"\n\nğŸ’­ Thought: {thought}")

            # æ£€æµ‹æ¨¡å‹æ˜¯å¦è¾“å‡º Final Answerï¼Œå¦‚æœæ˜¯çš„è¯ï¼Œç›´æ¥è¿”å›
            if "<final_answer>" in content:
                final_answer = re.search(r"<final_answer>(.*?)</final_answer>", content, re.DOTALL)
                return final_answer.group(1)

            # æ£€æµ‹ Action
            action_match = re.search(r"<action>(.*?)</action>", content, re.DOTALL)
            if not action_match:
                raise RuntimeError("æ¨¡å‹æœªè¾“å‡º <action>")

            try:
                # è§£æJSONæ ¼å¼çš„action
                action_data = json.loads(action_match.group(1).strip())
                tool_name = action_data["name"]
                tool_args = action_data["parameters"]
            except (json.JSONDecodeError, KeyError) as e:
                raise RuntimeError(f"å·¥å…·è°ƒç”¨æ ¼å¼é”™è¯¯: {str(e)}")

            print(f"\n\nğŸ”§ Action: {tool_name}({tool_args})")

            # åªæœ‰ç»ˆç«¯å‘½ä»¤æ‰éœ€è¦è¯¢é—®ç”¨æˆ·ï¼Œå…¶ä»–çš„å·¥å…·ç›´æ¥æ‰§è¡Œ
            should_continue = input(f"\n\næ˜¯å¦ç»§ç»­ï¼Ÿï¼ˆY/Nï¼‰") if tool_name == "run_terminal_command" else "y"
            if should_continue.lower() != 'y':
                print("\n\næ“ä½œå·²å–æ¶ˆã€‚")
                return "æ“ä½œè¢«ç”¨æˆ·å–æ¶ˆ"

            try:
                # è°ƒç”¨MCPå·¥å…·
                observation = await self.mcp_client.call_tool(tool_name, tool_args)
            except Exception as e:
                observation = f"å·¥å…·æ‰§è¡Œé”™è¯¯ï¼š{str(e)}"

            print(f"\n\nğŸ” Observationï¼š{observation}")
            obs_msg = f"<observation>{observation}</observation>"
            # æŠŠå·¥å…·æ‰§è¡Œç»“æœobservationæ·»åŠ åˆ°messageé‡Œ
            messages.append({"role": "user", "content": obs_msg})

    def render_system_prompt(self, system_prompt_template: str) -> str:
        """æ¸²æŸ“ç³»ç»Ÿæç¤ºæ¨¡æ¿ï¼Œæ›¿æ¢å˜é‡"""
        tool_list = self.tools if self.tools else "æ— "
        current_directory = self.project_directory
        return Template(system_prompt_template).substitute(
            operating_system = self.get_operating_system_name(),
            tool_list = tool_list,
            current_directory = current_directory
        )

    @staticmethod
    def get_api_key() -> str:
        """Load the API key from an environment variable."""
        load_dotenv()
        api_key = os.getenv("API_KEY")
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ° API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ã€‚")
        return api_key

    def call_model(self, messages):
        print("\n\næ­£åœ¨è¯·æ±‚æ¨¡å‹ï¼Œè¯·ç¨ç­‰...")
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            tools = self.tools,
        )
        content = response.choices[0].message.content
        messages.append({"role": "assistant", "content": content})
        return content

    def get_operating_system_name(self):
        os_map = {
            "Darwin": "macOS",
            "Windows": "Windows",
            "Linux": "Linux"
        }

        return os_map.get(platform.system(), "Unknown")


async def main():
    """ä¸»å‡½æ•°"""
    project_dir = os.path.abspath(os.path.dirname(__file__))

    # è·å– MCP æœåŠ¡å™¨è·¯å¾„
    mcp_server_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "mcp_server.py"))

    if not os.path.exists(mcp_server_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ° MCP æœåŠ¡å™¨è„šæœ¬ {mcp_server_path}")
        return

    try:
        # åˆ›å»º MCP å®¢æˆ·ç«¯å¹¶è¿æ¥
        async with MCPClient(mcp_server_path) as mcp_client:
            # åˆ›å»º Agent å¹¶åˆå§‹åŒ–
            agent = ReActAgent(mcp_client=mcp_client, model="qwen3-coder-plus", project_directory=project_dir)
            await agent.initialize()

            task = input("è¯·è¾“å…¥ä»»åŠ¡ï¼š")
            final_answer = await agent.run(task)
            print(f"\n\nâœ… Final Answerï¼š{final_answer}")

    except Exception as e:
        print(f"è¿è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
